{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Project.ipynb","provenance":[],"collapsed_sections":["jsqJRWukT4E-","4waR2bphUJiW","Wg111f2hUV8O"]},"kernelspec":{"name":"python3","display_name":"Python 3"},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"VEBhULS0s5Hp","colab_type":"text"},"source":["#The Project"]},{"cell_type":"markdown","metadata":{"id":"_FRax-9L5vjv","colab_type":"text"},"source":["Nelson CURIER-DUARTE                                           \n","Franck NGOUNOU KOTCHAP\n"]},{"cell_type":"code","metadata":{"id":"6wnWtnxvUOnw","colab_type":"code","colab":{}},"source":["import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torchvision import datasets, transforms\n","from functools import partial\n","from torch.utils.data import TensorDataset, DataLoader\n","import matplotlib.pyplot as plt\n","import numpy as np\n","import torchvision\n","from skimage import transform\n","import pdb"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"I3UvCjDMTurY","colab_type":"text"},"source":["##The Model"]},{"cell_type":"markdown","metadata":{"id":"2b8_WGw9iz7P","colab_type":"text"},"source":["La classe ConvolutionalNetwork  est composé de 3 champs qui nous seront utiles :</br>\n","- conv : Initialise les champs de la fonction Conv2d qui est la fonction de convolution.</br>\n","  * in_channels ici aura une valeur qui sera comprise entre 1 et 3 (1 si noir et blanc et 3 si en couleur (R G B))</br>\n","  * out_channel</br>\n","  * kernel size correspond a la taille que la fênetre aura pour chaque case de la matrice de convolution :</br>\n","par exemple : on a une matrice <table><tr><td>1</td> <td>2</td> <td>3</td></tr><tr><td> 3</td> <td>0</td> <td>1</td></tr> <tr> <td>1</td> <td>1</td> <td>0</td>  </tr><table>et on a un kernel (une matrice) 2*2 composé de chiffre (0 1 | 0 2), donc on va parcourir cette matrice avec un pas (padding que l'on vera après) avec le filtre et en calculant.</br>\n","par exemple   ici on aura donc la matrice <table><tr> <td>2</td> <td>4</td> </tr> <tr><td>2</td> <td>1</td></tr></table>  car on a 0x1 + 1x2 +3x0 + 0x2 = 2 on suit le même exemple pour le reste</br>\n","  * padding indique le pas qu'aura le filtre quand il parcourera la matrice cible par exemple si on a (1,1) il la parcoura de 1 en 1  </br>\n","             \n","        \n","- Une fonction d'activation qui nous permettra en quelque sorte de normaliser les valeurs contenu dans la matrice, par exemple la fonction d'activation <i>reLu</i> qui permettra de supprimer les valeur négative de la matrice. </br>\n","- Une fonction dropout qui est une fonction de normalisation. Cette fonction permet de désactiver certains neurones au hasard et d'éviter donc au réseau de neurone d'apprendre par coeur les images pendant l'entrainement et donc d'avoir de meilleurs résultats."]},{"cell_type":"code","metadata":{"id":"ikaL8AJsQav3","colab_type":"code","colab":{}},"source":["class ConvolutionalNetwork(nn.Module):\n","  \"\"\" A Convolution Network with dropout and a activation \"\"\"\n","  def __init__(self, in_channels, out_channels, kernel_size, padding, dropout_p, activation):\n","    super(ConvolutionalNetwork, self).__init__()\n","    self.conv = nn.Conv2d(\n","        in_channels= in_channels, \n","        out_channels= out_channels,\n","        kernel_size= kernel_size,\n","        padding= padding\n","        )\n","    self.activation = activation\n","    self.drop = nn.Dropout(\n","        p = dropout_p\n","        )\n","\n","  def forward(self, x):\n","        x = self.conv(x)\n","        x = self.drop(x)\n","        x = F.relu(x)\n","        x = self.activation(x)\n","        return x\n","        \n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"9XJsJr0Sioth","colab_type":"text"},"source":["Avec la classe LinearNetwork nous avons la définition d'un réseau de neurone classique.\n","- layer prend en argument nn.Linear composé du nombre de neurone en entrée et en sortie. En entrée nous avons en général le nombre de pixel contenue dans l'image que nous voulons analyser\n","par exemple une image 28 * 28 on entre tout simplement 28*28 et en sortie on peut mettre ce que l'on veut.\n","- Nous avons ensuite une fonction dropout comme vu précédemment ainsi qu'une fonction d'activation."]},{"cell_type":"code","metadata":{"id":"wFVFfX0gYi41","colab_type":"code","colab":{}},"source":["class LinearNetwork(nn.Module):\n","  \"\"\" A layer network with dropout and an activation function\"\"\"\n","  def __init__(self, in_features, out_features, dropout_p, activation):\n","    super(LinearNetwork, self).__init__()\n","    self.layer = nn.Linear(\n","        in_features = in_features,\n","         out_features= out_features\n","         )\n","    self.drop = nn.Dropout(\n","        p = dropout_p\n","    )\n","    self.activation= activation\n","\n","  def forward(self, x):\n","      x = self.layer(x)\n","      x = self.drop(x)\n","      x = self.activation(x)\n","      return x"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"y_xsuiDXsEzh","colab_type":"text"},"source":["\n","La class ImageNetwork est un reseau de neurones qui contient:\n","- 2 ConvolutionalNetwork:\n"," * La premère (les inputs) prend en entrée un nombre de channels qui continent des images de 7x7 pixels et a pour fonction d'activation une interpolation au plus proche voisin qui double la taille des images.</br> Par exemple pour une matrice 2x2:\n","  <table>\n","  <tr> <td>4</td> <td>6</td> </tr> \n","  <tr> <td>2</td> <td>1</td> </tr>\n","  </table>\n","  l'interpolation au voisin le plus proche dupliquera les valeurs  de la matrice 2x2 pour obtenir une matrice 4x4:\n","   <table>\n","   <tr> <td>4</td> <td>4</td> <td>6</td> <td>6</td> </tr>\n","   <tr> <td>4</td> <td>4</td> <td>6</td> <td>6</td> </tr>  \n","   <tr> <td>2</td> <td>2</td> <td>1</td> <td>1</td> </tr>\n","   <tr> <td>2</td> <td>2</td> <td>1</td> <td>1</td> </tr>\n","   </table>\n","Il renvoi ensuite un certain nombre de <i>channels</i>.</br>\n","  * La seconde prend des images de 14x14 et avec la fonction d'activation interpolation au plus proche voisin elle double les images à nouveau. Et renvoi un certain nombre de <i>channels</i>.\n","\n","- 1 LinearNetwork:\n","  * Celui-ci prend entre un tenseur de dimension nombre de batch x 28*28 *<i>channels</i> et renvoi une image de 28x28 pixels avec pour fonction d'activation la fonction sigmoïde.\n","\n","A la fin le model nous revoie une image en 2 dimentions en 28x28.\n","\n"]},{"cell_type":"code","metadata":{"id":"KVjlPHxIQrt2","colab_type":"code","colab":{}},"source":["class ImageNetwork(nn.Module):\n","   \"\"\"A image Network which take a 7x7 picture in input and \n","     give a 28x28 picture in output\n","  \"\"\"\n","  def __init__(self):\n","     super(ImageNetwork, self).__init__()\n","     self.conv_layer=nn.Sequential(\n","         ConvolutionalNetwork(\n","             in_channels = 1,\n","             out_channels = 32,\n","             kernel_size = 3,\n","             padding  = 1,\n","             dropout_p = .6, \n","             activation = partial(F.interpolate, size = (14,14)) # the activation double the size of the picture to 14x14\n","         ),\n","         ConvolutionalNetwork(\n","             in_channels = 32,\n","             out_channels = 64,\n","             kernel_size = 3,\n","             padding  = 1,\n","             dropout_p = .6,\n","             activation = partial(F.interpolate, size = (28, 28)) # the activation double the size again of the picture to 28x28\n","         )\n","     )\n","     self.linear_layer = nn.Sequential(\n","         LinearNetwork(\n","             in_features = 28 * 28 * 64, # the input of the flatten pictures\n","             out_features = 784, # the flatten picture 28 * 28\n","             dropout_p = 0,\n","             activation = torch.sigmoid # Sigmoid(x) = 1 / 1 + exp(-x) \n","        )\n","      )\n","     \n","\n","  def forward(self, x): # x = [batch, 1, 7, 7]\n","   \n","    x = self.conv_layer(x) # [batch, 64, 28 ,28]\n","    x = torch.flatten(x, 1) # [batch, 50176]\n","    x = self.linear_layer(x) # [batch, 784]\n","    x = x.view(x.shape[0], 1, 28, 28)  #[batch, 1, 28,28]\n","    return x"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"jsqJRWukT4E-","colab_type":"text"},"source":["##The resize function and draw image function"]},{"cell_type":"markdown","metadata":{"id":"K6lIR7zdiepD","colab_type":"text"},"source":["La fonction resize va nous permettre de redimmensionner de leur taille initial a 7x7. En regardant le code \n","   en détail, on remarque que l'on utilise ici le cpu pour optimiser la performance et  après la transformation\n","   on précide que le tenseur sera stocker sur le processeur cuda "]},{"cell_type":"code","metadata":{"id":"piDFpgJwVrIF","colab_type":"code","colab":{}},"source":["def resize(x):\n","  \"\"\"Resize the 28x28 picture in a 7x7\"\"\"\n","  xx = x.cpu() #[batch, 1, 28,28]\n","  xx = np.transpose(xx, (2, 3, 1, 0))  #[28,28,1, batch]\n","  xx = transform.resize(xx.reshape(28, 28, -1), (7, 7)) # resize the picture to 7x7 [7, 7, batch]\n","  xx = xx.reshape(7, 7, 1, -1) #[7, 7, 1, batch]\n","  xx = np.transpose(xx, (3, 2, 0, 1) ) # [batch, 1, 7, 7]\n","  return torch.Tensor(xx).cuda()\n","\n","def imshow(inp, org,title=None):\n","    \"\"\"Imshow for Tensor.\"\"\"\n","    inp = torch.cat([inp[0][0].cpu(), org[0][0].cpu()], dim=1) # Concatenate  the two pictures to the horizontal\n","    plt.imshow(inp.cpu().detach(), cmap='gray')\n","    if title is not None:\n","        plt.title(title)\n","    plt.pause(0.001)  # pause a bit so that plots are updated"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"4waR2bphUJiW","colab_type":"text"},"source":["##The training and eval function"]},{"cell_type":"markdown","metadata":{"id":"0bgCniwGiN1L","colab_type":"text"},"source":["La fonction d'évaluation permet de tester le réseau de neurones avec des images qu'il n'a encore jamais vu.\n","  Danc celle-ci nous affichons a un certains moment l'image durant les 3 étapes crutiale pour bien comprendre le fonctionnement :</br>\n","L'image avant la transformation au format 7x7 , celle après la transformation et celle après être passé dans le réseau de neurone  "]},{"cell_type":"code","metadata":{"id":"CXd293hFU58T","colab_type":"code","colab":{}},"source":["def eval(model, criterion, device, loader, n_batch = -1):\n","  model.eval()\n","  loss    = 0\n","  total_pred = 0\n","  with torch.no_grad():\n","      for batch_idx, (data, _) in enumerate(loader):\n","          if n_batch !=-1 and batch_idx == n_batch:\n","            break\n","          data = data.to(device)\n","          output = model(resize(data))\n","          if(batch_idx == 0): # show one example\n","            plt.imshow(resize(data)[0][0].cpu().detach(), cmap = 'gray')\n","            plt.show()\n","            imshow(output,data)\n","          loss        += criterion(output, data).item()  # sum up batch loss\n","          total_pred  += len(data)\n","  return loss / total_pred\n","\n","\n","\n","def train(model, epochs, optimizer, criterion, device, train_loader, test_loader):\n","  model.train()\n","  i = 0\n","  print('0% training')\n","  eval(model,criterion, device, train_loader,20)\n","  for epoch in  range(epochs):\n","    i = 0\n","    for batch_idx, (data, _) in enumerate(train_loader):\n","      data = data.to(device)\n","      optimizer.zero_grad()\n","      output = model(resize(data))\n","      loss = criterion(output,data)\n","      loss.backward()\n","      optimizer.step()\n","      if (i % 500 == 0):\n","        print((epoch/epochs)*100,\"% training\",sep='')\n","        print(f'[{epoch:4}] Train eval average loss: {eval(model,criterion, device, train_loader,20):.6}, Test eval average loss: {eval(model,criterion, device,test_loader):.4}')\n","\n","      i+=1;\n","\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wg111f2hUV8O","colab_type":"text"},"source":["##The create loader function"]},{"cell_type":"markdown","metadata":{"id":"MvRkZXvriKSz","colab_type":"text"},"source":["Cette fonction permet tout simplement de télécharger les images dans la base de donnée MNIST de google selon le fait qu'elles soient plus tard utilisé pour l'entrainement ou pour les tests. "]},{"cell_type":"code","metadata":{"id":"9is3fbgaVTHb","colab_type":"code","colab":{}},"source":["def create_loaders(datasetMNIST):\n","  \"\"\" Created a loader from the Mnist dataset given in argument\"\"\"\n","  mnist_transform = transforms.Compose([\n","    transforms.ToTensor()\n","  ])\n"," \n","  train_dataset = datasetMNIST(\n","    root      = '../data',\n","    train     = True,\n","    download  = True,\n","    transform = mnist_transform\n","  )\n","\n","  test_dataset = datasetMNIST(\n","    root      = '../data',\n","    train     = False,\n","    download  = True,\n","    transform = mnist_transform\n","  )\n","\n"," \n","  train_loader = DataLoader(train_dataset, batch_size = 64, shuffle = True)\n","  test_loader  = DataLoader(test_dataset, batch_size = 64, shuffle = True)\n","\n","  return train_loader, test_loader"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"HSByjnM0UcVu","colab_type":"text"},"source":["##The Main Function"]},{"cell_type":"markdown","metadata":{"id":"baupc-PZiATu","colab_type":"text"},"source":[" C'et ici que nous allons initialiser les paramètre qui seront utilisé par toutes les fonctions que nous avons vu précédemment.\n","  Tout d'abord nous initialisons les objet train_loaders (pour l'entrainement) et test_loaders (pour les tests) qui contiendront les iamges que nous utiliserons tout au long\n","  du programme:</br>\n","\n","  - epochs concerne le nombre d'entrainement que nous allons effectuer.\n","  - learning rate est tout simplement le taux d'apprentissage , c'est une sorte de bonus que l'on ajoute au calcul de la descente de gradient qui permet de l'accélérer plus ou moins selon sa valeur.\n","  - device correspond au \"support\" a utilisé (processeur etc) ici ce sera le processeur cuda.\n","  - Nous chargons le modèle qui sera utilisé ici et ensuite sur quel device celui-ci sera exécuté.\n","  - Ensuite nous définissons la fonction que nous voulons utiliser  qui permettra à notre réseau de neurone \"d'apprendre. Il en \n","  existes plusieurs qui fonctionne plus ou moins bien selon les donnée et autres. Ici on utilisera Adam qui a une excellente performacnce.\n","  - Nous définissons ensuite la fonction de loss qui permet de calculer la performance du réseau de neurone.\n","  - Finalement nous pouvons enfin lancer la fonction d'entrainement . "]},{"cell_type":"code","metadata":{"id":"PNs-8enPVV_s","colab_type":"code","colab":{}},"source":["def main():\n","  (\n","   train_loader,\n","   test_loader\n","  )=create_loaders(datasets.MNIST)\n","  epochs = 200\n","  learning_rate = 1e-2\n","  \n","  device = torch.device('cuda')\n","  model = ImageNetwork()\n","  model.to(device)\n","  optimizer = optim.Adam(model.parameters(),  lr = learning_rate)\n","  criterion = nn.MSELoss()\n","  train(model, epochs, optimizer, criterion, device, train_loader, test_loader)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"3TnLXT_pVaou","colab_type":"code","colab":{}},"source":["main()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Wt2Rl70lUhRP","colab_type":"text"},"source":["##1. Fashion MNIST"]},{"cell_type":"markdown","metadata":{"id":"iuiYmUVHr0y-","colab_type":"text"},"source":["C'est le même pricipe que pour le Mnist précedent. On utilise donc la classe ImageNetwork et à la fonction create_loaders on fait appel au dataset FashionMnist."]},{"cell_type":"code","metadata":{"id":"sEXGQrTUZFLg","colab_type":"code","colab":{}},"source":["def fashionMNIST():\n","  (\n","      train_loader,\n","   test_loader\n","   )=create_loaders(datasets.FashionMNIST)\n","  epochs = 200\n","  learning_rate = 1e-2\n","  \n","  device = torch.device('cuda')\n","  model = ImageNetwork()\n","  model.to(device)\n","  optimizer = optim.Adam(model.parameters(),  lr = learning_rate)\n","  criterion = nn.MSELoss()\n","  train(model, epochs, optimizer, criterion, device, train_loader, test_loader)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"7pDvytEcQ1t0","colab_type":"code","colab":{}},"source":["fashionMNIST()"],"execution_count":0,"outputs":[]}]}